{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as numpy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize the data in the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.utils import shuffle \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLP Preprocessing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import unicodedata as udata\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "checking the versions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20.0\n",
      "3.0.2\n",
      "1.14.6\n",
      "0.23.4\n",
      "3.3\n"
     ]
    }
   ],
   "source": [
    "print(sklearn.__version__)\n",
    "print(matplotlib.__version__)\n",
    "print(numpy.__version__)\n",
    "print(pd.__version__)\n",
    "print(nltk.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"TwitterSentimentAnalysis.csv\", encoding='latin-1', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffling the data in the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Give column names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assigning the Columns name to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [\"sentiment\", \"id\", \"date\", \"query\", \"user\", \"text\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sentiment', 'id', 'date', 'query', 'user', 'text'], dtype='object')"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking Null values in the dataset. Here we are counting each cloumn null values in the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment    0\n",
       "id           0\n",
       "date         0\n",
       "query        0\n",
       "user         0\n",
       "text         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the duplicates values and counting duplicates in the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get the first 5 rows from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>1880323927</td>\n",
       "      <td>Fri May 22 00:50:28 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>IHCF</td>\n",
       "      <td>i love you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>2059478439</td>\n",
       "      <td>Sat Jun 06 17:00:58 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>cryst0clearre</td>\n",
       "      <td>yaY! my phone is back on!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1693379887</td>\n",
       "      <td>Sun May 03 22:22:17 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>b2therooke</td>\n",
       "      <td>@espisc thanks!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1835593196</td>\n",
       "      <td>Mon May 18 06:20:19 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>AmandaGierusz</td>\n",
       "      <td>I watched the best workout show this morning i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2228331816</td>\n",
       "      <td>Thu Jun 18 14:18:26 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>fshoemark_smith</td>\n",
       "      <td>Last  day of college today and I already miss ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment          id                          date     query  \\\n",
       "0          4  1880323927  Fri May 22 00:50:28 PDT 2009  NO_QUERY   \n",
       "1          4  2059478439  Sat Jun 06 17:00:58 PDT 2009  NO_QUERY   \n",
       "2          4  1693379887  Sun May 03 22:22:17 PDT 2009  NO_QUERY   \n",
       "3          4  1835593196  Mon May 18 06:20:19 PDT 2009  NO_QUERY   \n",
       "4          0  2228331816  Thu Jun 18 14:18:26 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user                                               text  \n",
       "0             IHCF                                        i love you   \n",
       "1    cryst0clearre                         yaY! my phone is back on!   \n",
       "2       b2therooke                                   @espisc thanks!   \n",
       "3    AmandaGierusz  I watched the best workout show this morning i...  \n",
       "4  fshoemark_smith  Last  day of college today and I already miss ...  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "drop some column from the dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"id\", \"date\", \"query\", \"user\"], axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>i love you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>yaY! my phone is back on!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>@espisc thanks!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>I watched the best workout show this morning i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Last  day of college today and I already miss ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text\n",
       "0          4                                        i love you \n",
       "1          4                         yaY! my phone is back on! \n",
       "2          4                                   @espisc thanks! \n",
       "3          4  I watched the best workout show this morning i...\n",
       "4          0  Last  day of college today and I already miss ..."
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " count the number of sentiments with respect to their tweet (4 stands for positive tweet and 0 stands for negative tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    800000\n",
       "0    800000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Cleaning data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add new column pre_clean_len to dataframe which is length of each tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pre_clean_len'] = [len(t) for t in df.text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding outliers using Box plot using pre_clean_len column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot(df.pre_clean_len)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check for any tweets greater than 140 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>pre_clean_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4</td>\n",
       "      <td>@briannalicia To regain focus. Change location...</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0</td>\n",
       "      <td>@LuisCamachoJr Nice to hear from you was busy ...</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>0</td>\n",
       "      <td>I'm up still,can't sleep&amp;amp;thinkin about jes...</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>0</td>\n",
       "      <td>Russian Roulette is not the same without a gun...</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>4</td>\n",
       "      <td>@tommcfly Hi! i and another 10 girls have shou...</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>4</td>\n",
       "      <td>Can't stop listening to the &amp;quot;Once&amp;quot; s...</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>4</td>\n",
       "      <td>@IamDrewMoney I'm pretty positive that it'll s...</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>4</td>\n",
       "      <td>.@Gartnergreg Hm. Tsar, czar _&amp;amp;_ Kaiser al...</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>4</td>\n",
       "      <td>SHE'S on a BOAT-cue the music..&amp;quot;Watch the...</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>4</td>\n",
       "      <td>@helenthornber &amp;quot;what a wonderful world it...</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentiment                                               text  \\\n",
       "19            4  @briannalicia To regain focus. Change location...   \n",
       "120           0  @LuisCamachoJr Nice to hear from you was busy ...   \n",
       "201           0  I'm up still,can't sleep&amp;thinkin about jes...   \n",
       "276           0  Russian Roulette is not the same without a gun...   \n",
       "502           4  @tommcfly Hi! i and another 10 girls have shou...   \n",
       "641           4  Can't stop listening to the &quot;Once&quot; s...   \n",
       "736           4  @IamDrewMoney I'm pretty positive that it'll s...   \n",
       "909           4  .@Gartnergreg Hm. Tsar, czar _&amp;_ Kaiser al...   \n",
       "980           4  SHE'S on a BOAT-cue the music..&quot;Watch the...   \n",
       "1333          4  @helenthornber &quot;what a wonderful world it...   \n",
       "\n",
       "      pre_clean_len  \n",
       "19              141  \n",
       "120             146  \n",
       "201             146  \n",
       "276             141  \n",
       "502             148  \n",
       "641             146  \n",
       "736             141  \n",
       "909             150  \n",
       "980             143  \n",
       "1333            144  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.pre_clean_len > 140].head(10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage, if you want you could remove these outlier tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Importing beautiful soup\n",
    "#remove @ mentions from tweets\n",
    "#remove URLs from tweets\n",
    "#converting words like isn't to is not\n",
    "#get only text from the tweets \n",
    "#remove utf-8-sig code\n",
    "#converting all into lower case\n",
    "#will replace non-alphabetic characters by space\n",
    "#Word Punct Tokenize and only consider words whose length is greater than 1\n",
    "#join the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "tok = WordPunctTokenizer()\n",
    "\n",
    "pat1 = r'@[A-Za-z0-9_]+'        # remove @ mentions from tweets\n",
    "pat2 = r'https?://[^ ]+'        # remove URLs from tweets\n",
    "combined_pat = r'|'.join((pat1, pat2)) #addition of pat1 and pat2\n",
    "www_pat = r'www.[^ ]+'         # remove URLs from tweets\n",
    "negations_dic = {\"isn't\":\"is not\", \"aren't\":\"are not\", \"wasn't\":\"was not\", \"weren't\":\"were not\",   # converting words like isn't to is not\n",
    "                \"haven't\":\"have not\",\"hasn't\":\"has not\",\"hadn't\":\"had not\",\"won't\":\"will not\",\n",
    "                \"wouldn't\":\"would not\", \"don't\":\"do not\", \"doesn't\":\"does not\",\"didn't\":\"did not\",\n",
    "                \"can't\":\"can not\",\"couldn't\":\"could not\",\"shouldn't\":\"should not\",\"mightn't\":\"might not\",\n",
    "                \"mustn't\":\"must not\"}\n",
    "neg_pattern = re.compile(r'\\b(' + '|'.join(negations_dic.keys()) + r')\\b')\n",
    "\n",
    "def tweet_cleaner(text):  # define tweet_cleaner function to clean the tweets\n",
    "    soup = BeautifulSoup(text, 'lxml')    # create beautiful soup object\n",
    "    souped = soup.get_text()   # get only text from the tweets \n",
    "    try:\n",
    "        bom_removed = souped.decode(\"utf-8-sig\").replace(u\"\\ufffd\", \"?\")    # remove utf-8-sig code\n",
    "    except:\n",
    "        bom_removed = souped\n",
    "    stripped = re.sub(combined_pat, '', bom_removed) # calling combined_pat\n",
    "    stripped = re.sub(www_pat, '', stripped) #remove URLs\n",
    "    lower_case = stripped.lower()      # converting all into lower case\n",
    "    neg_handled = neg_pattern.sub(lambda x: negations_dic[x.group()], lower_case) # converting words like isn't to is not\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", neg_handled)       # will replace # by space\n",
    "    words = [x for x  in tok.tokenize(letters_only) if len(x) > 1] # Word Punct Tokenize and only consider words whose length is greater than 1\n",
    "    return (\" \".join(words)).strip() # join the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.0024759769439697266\n",
      "10000 2.872504711151123\n",
      "20000 5.62529444694519\n",
      "30000 8.349005460739136\n",
      "40000 11.006449460983276\n"
     ]
    }
   ],
   "source": [
    "#Note that we have 1600000 instances. But processing so many instances will take a very very long time.\n",
    "#Hence, restricting to rather 50000 instances.\n",
    "limit=50000\n",
    "import time; \n",
    "ms = time.time()\n",
    "#nums = [0,400000,800000,1200000,1600000] # used for batch processing tweets\n",
    "#nums = [0, 9999]\n",
    "clean_tweet_texts = [] # initialize list\n",
    "for i in range(0,limit): # batch process 1.6 million tweets \n",
    "    if i % 10000==0:\n",
    "        print(i, time.time()-ms)\n",
    "    clean_tweet_texts.append(tweet_cleaner(df['text'][i]))  # call tweet_cleaner function and pass parameter as all the tweets to clean the tweets and append cleaned tweets into clean_tweet_texts list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# clean_tweet_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tokenize word in clean_tweet_texts and append it to word_tokens list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokens = [] # initialize list for tokens\n",
    "for word in clean_tweet_texts:  # for each word in clean_tweet_texts\n",
    "    word_tokens.append(word_tokenize(word)) #tokenize word in clean_tweet_texts and append it to word_tokens list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = [] # initialize list df1 to store words after lemmatization\n",
    "from nltk.stem import WordNetLemmatizer # import WordNetLemmatizer from nltk.stem\n",
    "lemmatizer = WordNetLemmatizer() # create an object of WordNetLemmatizer\n",
    "for l in word_tokens: # for loop for every tokens in word_token\n",
    "    b = [lemmatizer.lemmatize(q) for q in l] #for every tokens in word_token lemmatize word and giev it to b\n",
    "    df1.append(b) #append b to list df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df1 =[] # initialize list clean_df1 to join word tokens after lemmatization\n",
    "for c in df1:  # for loop for each list in df1\n",
    "    a = \" \".join(c) # join words in list with space in between and give it to a\n",
    "    clean_df1.append(a) # append a to clean_df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# clean_df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert clean_tweet_texts into dataframe and name it as clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = pd.DataFrame(clean_df1,columns=['text']) # convert clean_tweet_texts into dataframe and name it as clean_df\n",
    "#clean_df['target'] = df.sentiment[:10000] # from earlier dataframe get the sentiments of each tweet and make a new column in clean_df as target and give it all the sentiment score\n",
    "#clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df['clean_len'] = [len(t) for t in clean_df.text] # Again make a new coloumn in the dataframe and name it as clean_len which "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [text, clean_len]\n",
       "Index: []"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df[clean_df.clean_len > 140].head(10) # again check if any tweet is more than 140 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>pre_clean_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>i love you</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>yaY! my phone is back on!</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>@espisc thanks!</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>I watched the best workout show this morning i...</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Last  day of college today and I already miss ...</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text  pre_clean_len\n",
       "0          4                                        i love you              11\n",
       "1          4                         yaY! my phone is back on!              26\n",
       "2          4                                   @espisc thanks!              16\n",
       "3          4  I watched the best workout show this morning i...             73\n",
       "4          0  Last  day of college today and I already miss ...             53"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target2 = [] # initialize list\n",
    "for i in range(0,limit): # batch process 1.6 million tweets \n",
    "    target2.append(df['sentiment'][i])\n",
    "clean_df['target']=target2\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000,)\n",
      "(50000,)\n",
      "{0, 4}\n",
      "dict_values([24864, 25136])\n"
     ]
    }
   ],
   "source": [
    "X = clean_df.text # get all the text in x variable\n",
    "y = clean_df.target # get all the sentiments into y variable\n",
    "print(X.shape) #print shape of x\n",
    "print(y.shape) # print shape of y\n",
    "from collections import Counter\n",
    "print(set(y)) # equals to list(set(words))\n",
    "print(Counter(y).values()) #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# perform train and test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_train is the tweets of training data, X_test is the testing tweets which we have to predict, y_train is the sentiments of tweets in the traing data and y_test is the sentiments of the tweets  which we will use to measure the accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection  import train_test_split #from sklearn.cross_validation import train_test_split to split the data into training and tesing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state= 1) # split the data into traing and testing set where ratio is 80:20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Get Tf-idf object and save it as vect. We can select features from here we just have simply change \n",
    "#the ngram range to change the features also we can remove stop words over here with the help of stop parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(analyzer = \"word\", ngram_range=(1,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fit or training data tweets to vect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transform our training data tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect.fit(X_train) \n",
    "X_train_dtm = vect.transform(X_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transform our testing data tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_dtm = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB # import Multinomial Naive Bayes model from sklearn.naive_bayes\n",
    "nb = MultinomialNB(alpha = 10) # get object of Multinomial naive bayes model with alpha parameter = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=10, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.fit(X_train_dtm, y_train)# fit our both training data tweets as well as their sentiments to the multinomial naive bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7524246813952925"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score  # import cross_val_score from sklear.model_selection\n",
    "accuracies = cross_val_score(estimator = nb, X = X_train_dtm, y = y_train, cv = 10) # do K- fold cross validation on our traing data and its sentimenst with 10 fold cross validation\n",
    "accuracies.mean() # measure the mean accuray of 10 fold cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predict the sentiments of testing data tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_nb = nb.predict(X_test_dtm) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "measure the accuracy of our model on the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7623"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics # import metrics from sklearn\n",
    "metrics.accuracy_score(y_test, y_pred_nb) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot the confusion matrix between our predicted sentiments and the original testing data sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4441,  621],\n",
       "       [1756, 3182]])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix # import confusion matrix from the sklearn.metrics\n",
    "confusion_matrix(y_test, y_pred_nb) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression # import Logistic Regression model from sklearn.linear_model\n",
    "logisticRegr = LogisticRegression(C = 1.1) # get object of logistic regression model with cost parameter = 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisticRegr.fit(X_train_dtm, y_train)# fit our both traing data tweets as well as its sentiments to the logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.77572563880004"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score # import cross_val_score from sklear.model_selection\n",
    "accuracies = cross_val_score(estimator = logisticRegr, X = X_train_dtm, y = y_train, cv = 10) # do K- fold cross validation on our traing data and its sentimenst with 10 fold cross validation\n",
    "accuracies.mean() # measure the mean accuray of 10 fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lg = logisticRegr.predict(X_test_dtm)  # predict the sentiments of testing data tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7776"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics # import metrics from sklearn\n",
    "metrics.accuracy_score(y_test, y_pred_lg) # measure the accuracy of our model on the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4077,  985],\n",
       "       [1239, 3699]])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix # import confusion matrix from the sklearn.metrics\n",
    "confusion_matrix(y_test, y_pred_lg) # plot the confusion matrix between our predicted sentiments and the original testing data sentiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC # import SVC model from sklearn.svm\n",
    "svm_clf = LinearSVC(random_state=0) # get object of SVC model with random_state parameter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf.fit(X_train_dtm, y_train)# fit our both traing data tweets as well as its sentiments to the SVC model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7842003391968962"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score  # import cross_val_score from sklear.model_selection\n",
    "accuracies = cross_val_score(estimator = svm_clf, X = X_train_dtm, y = y_train, cv = 10)# do K- fold cross validation on our traing data and its sentimenst with 10 fold cross validation\n",
    "accuracies.mean() # measure the mean accuray of 10 fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svm = svm_clf.predict(X_test_dtm)  # predict the sentiments of testing data tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7867"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics  # import metrics from sklearn\n",
    "metrics.accuracy_score(y_test, y_pred_svm)  # measure the accuracy of our model on the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4100,  962],\n",
       "       [1171, 3767]])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix # import confusion matrix from the sklearn.metrics\n",
    "confusion_matrix(y_test, y_pred_svm)# plot the confusion matrix between our predicted sentiments and the original testing data sentiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf_dtc = DecisionTreeClassifier(random_state = 100, max_depth=3, min_samples_leaf=5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=5, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=100,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_dtc.fit(X_train_dtm, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5758001475453217"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score \n",
    "accuracies = cross_val_score(estimator = clf_dtc, X = X_train_dtm, y = y_train, cv = 10)\n",
    "accuracies.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dtc = clf_dtc.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5663"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "metrics.accuracy_score(y_test, y_pred_dtc) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1194, 3868],\n",
       "       [ 469, 4469]])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, y_pred_dtc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf_boost = AdaBoostClassifier(n_estimators=100, base_estimator=None,learning_rate=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_boost.fit(X_train_dtm, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7161248358468647"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score \n",
    "accuracies = cross_val_score(estimator = clf_boost, X = X_train_dtm, y = y_train, cv = 10)\n",
    "accuracies.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_boost = clf_boost.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7284"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "metrics.accuracy_score(y_test, y_pred_boost) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3403, 1659],\n",
       "       [1057, 3881]])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, y_pred_boost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf_rf = RandomForestClassifier(n_estimators = 100, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_rf.fit(X_train_dtm, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7609249755187484"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score \n",
    "accuracies = cross_val_score(estimator = clf_rf, X = X_train_dtm, y = y_train, cv = 10)\n",
    "accuracies.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf = clf_rf.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7637"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "metrics.accuracy_score(y_test, y_pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3814, 1248],\n",
       "       [1115, 3823]])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, y_pred_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nearest Neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "clf_knn = KNeighborsClassifier(n_neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_knn.fit(X_train_dtm, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5163256757812923"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score \n",
    "accuracies = cross_val_score(estimator = clf_knn, X = X_train_dtm, y = y_train, cv = 10)\n",
    "accuracies.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_knn = clf_knn.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5347"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "metrics.accuracy_score(y_test, y_pred_knn) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2462, 2600],\n",
       "       [2053, 2885]])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, y_pred_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
